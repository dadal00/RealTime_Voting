receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

processors:
  batch:
    send_batch_size: 1000
    timeout: 10s
  # servicegraph:
  #   metrics_exporter: prometheus
  #   latency_histogram_buckets: [100ms, 500ms, 1s, 2.5s, 5s, 10s]

exporters:
  logging:
    loglevel: info                # debug > info > warning > error > fatal
  otlp/tempo:
    endpoint: tempo:4319
    tls:
      insecure: true

service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [batch] #, servicegraph]
      exporters: [otlp/tempo, logging]
    # metrics:
    #   receivers: [prometheus]
    #   exporters: [prometheus]
